_format_version: '3.0'
_konnect:
  control_plane_name: kong-aws
services:
- name: ai-proxy
  url: http://localhost:65535
  routes:
  - name: openai-chat
    paths:
    - /
plugins:
- name: ai-proxy-advanced
  instance_name: ai-proxy-advanced-bedrock
  config:
    targets:
    - logging:
        log_statistics: true
      route_type: llm/v1/chat
      #model:
      #  name: gpt-4o
      #  provider: openai
      #  options:
      #    max_tokens: 512
      #    temperature: 1.0
      auth:
        param_name: "allow_override"
        param_value: "false"
        param_location: "body"
      model:
        #name: "us.amazon.nova-lite-v1:0"
        name: "us.amazon.nova-micro-v1:0"
        provider: bedrock
        options:
          bedrock:
            aws_region: "us-east-2"
- name: ai-rag-injector
  id: 3194f12e-60c9-4cb6-9cbc-c8fd7a00cff1
  instance_name: ai-rag-injector-bedrock
  config:
    inject_template: |
      Only use the following information surrounded by <CONTEXT></CONTEXT> and your existing knowledge to provide the best possible answer to the user.
      <CONTEXT><RAG RESPONSE></CONTEXT>
      User's question: <PROMPT>
    #fetch_chunks_count: 5
    embeddings:
      #auth:
      #  header_name: Authorization
      #  header_value: Bearer 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
      #model:
      #  provider: openai
      #  name: text-embedding-3-large
      auth:
        param_name: "allow_override"
        param_value: "false"
        param_location: "body"
      model:
        provider: bedrock
        name: "amazon.titan-embed-text-v2:0"
        options:
          bedrock:
            aws_region: "us-east-2"
    vectordb:
      strategy: redis
      redis:
        host: redis-stack.redis
        port: 6379
      distance_metric: cosine
      #dimensions: 768
      dimensions: 1024
