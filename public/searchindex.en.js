var relearn_searchindex = [
  {
    "breadcrumb": "API Management with Kong Konnect",
    "content": "The Kong Konnect platform provides a cloud control plane (CP), which manages all service configurations. It propagates those configurations to all Runtime control planes, which use in-memory storage. These nodes can be installed anywhere, on-premise or in AWS.\nFor today workshop, we will be focusing on Kong Gateway. Kong Gateway data plane listen for traffic on the proxy port 443 by default. The data plane evaluates incoming client API requests and routes them to the appropriate backend APIs. While routing requests and providing responses, policies can be applied with plugins as necessary.\nKonnect modules Kong Konnect Enterprise features are described in this section, including modules and plugins that extend and enhance the functionality of the Kong Konnect platform.\nControl Plane (Gateway Manager) Control Plane empowers your teams to securely collaborate and manage their own set of runtimes and services without the risk of impacting other teams and projects. Control Plane instantly provisions hosted Kong Gateway control planes and supports securely attaching Kong Gateway data planes from your cloud or hybrid environments.\nThrough the Control Plane, increase the security of your APIs with out-of-the-box enterprise and community plugins, including OpenID Connect, Open Policy Agent, Mutual TLS, and more.\nDev Portal Streamline developer onboarding with the Dev Portal, which offers a self-service developer experience to discover, register, and consume published services from your Service Hub catalog. This customizable experience can be used to match your own unique branding and highlights the documentation and interactive API specifications of your services. Enable application registration to automatically secure your APIs with a variety of authorization providers.\nAnalytics Use Analytics to gain deep insights into service, route, and application usage and health monitoring data. Keep your finger on the pulse of the health of your API products with custom reports and contextual dashboards. In addition, you can enhance the native monitoring and analytics capabilities with Kong Gateway plugins that enable streaming monitoring metrics to third-party analytics providers.\nTeams To help secure and govern your environment, Konnect provides the ability to manage authorization with teams. You can use Konnect’s predefined teams for a standard set of roles, or create custom teams with any roles you choose. Invite users and add them to these teams to manage user access. You can also map groups from your existing identity provider into Konnect teams.\nFurther Reading Gateway Manager Dev Portal Analytics asdad",
    "description": "The Kong Konnect platform provides a cloud control plane (CP), which manages all service configurations. It propagates those configurations to all Runtime control planes, which use in-memory storage. These nodes can be installed anywhere, on-premise or in AWS.\nFor today workshop, we will be focusing on Kong Gateway. Kong Gateway data plane listen for traffic on the proxy port 443 by default. The data plane evaluates incoming client API requests and routes them to the appropriate backend APIs. While routing requests and providing responses, policies can be applied with plugins as necessary.",
    "tags": [],
    "title": "Kong Konnect Architectural Overview",
    "uri": "/architecture/index.html"
  },
  {
    "breadcrumb": "API Management with Kong Konnect",
    "content": "This chapter will walk you through the pre-requisites.\nKong Konnect Subscription You will need a Kong Konnect Subscription to execute this workshop.\nIf you want to check the Konnect Pricing and Plans, please, redirect to https://konghq.com/pricing\nCommand Line Utilities In this workshop, we will use the following command line utilities\nkubectl (we will install this in subsequent section) curl (pre-installed) jq (we will install this in subsequent section)",
    "description": "This chapter will walk you through the pre-requisites.\nKong Konnect Subscription You will need a Kong Konnect Subscription to execute this workshop.\nIf you want to check the Konnect Pricing and Plans, please, redirect to https://konghq.com/pricing\nCommand Line Utilities In this workshop, we will use the following command line utilities\nkubectl (we will install this in subsequent section) curl (pre-installed) jq (we will install this in subsequent section)",
    "tags": [],
    "title": "Pre-Requisites",
    "uri": "/10-pre-requisites/index.html"
  },
  {
    "breadcrumb": "API Management with Kong Konnect \u003e Pre-Requisites",
    "content": "Konnect Plus Subscription You will need a Konnect subscription. Follow the steps below to obtain a Konnect Plus subscription. Initially $500 of credits are provided for up to 30 days, after the credits have expired or the time has finished Konnect Plus will charge based on Konnect Plus pricing. Following the workshop instructions will use less than $500 credits. After the workshop has finished the Konnect Plus environment can be deleted.\nClick on the Registration link and present your credentials.\nKonnect will send you an email to confirm the subscription. Click on the link in email to confirm your subscription.\nThe Konnect environment can be accessed via the Konnect log in page.\nAfter logging in create an organisation name, select a region, then answer a few questions.\nCredit available can be monitored though Plan and Usage page.",
    "description": "Konnect Plus Subscription You will need a Konnect subscription. Follow the steps below to obtain a Konnect Plus subscription. Initially $500 of credits are provided for up to 30 days, after the credits have expired or the time has finished Konnect Plus will charge based on Konnect Plus pricing. Following the workshop instructions will use less than $500 credits. After the workshop has finished the Konnect Plus environment can be deleted.",
    "tags": [],
    "title": "Konnect Subscription",
    "uri": "/10-pre-requisites/konnect-control-plane/index.html"
  },
  {
    "breadcrumb": "API Management with Kong Konnect \u003e Pre-Requisites",
    "content": "Access to Amazon Bedrock foundation models isn’t granted by default. In order to gain access to the foundational model, follow the steps below.\n:::alert{header=“Model providers” type=“info”} As part of this workshop we will utilize model provider from Amazon, Anthropic, and Cohere. Access to Amazon Titan model is available by default. Access to model in different AWS regions may vary, please refer to the model support by AWS region. :::\nFrom the AWS console, navigate to Amazon Bedrock.\nSelect Enable specific models.\n:::alert{header=“Specific Model” type=“warning”} Please note, during a hosted event such as re:Invent, Kubecon, Immersion Day, or any other event hosted by AWS or Kong, where are provided with temporary AWS account, you are limited to subscribing to 5 third-party models at most. Do NOT select “Enable all models” as it may result in termination of the AWS accounts that you are using during these events. :::\nChoose the following models:\nAmazon: Nova Lite - amazon.nova-lite-v1:0 Nova Micro - amazon.nova-micro-v1:0 Titan Text Embeddings V2 - amazon.titan-embed-text-v2:0 Meta: Llama 3.3 70B Instruct v1 - meta.llama3-3-70b-instruct-v1:0 Select Next to review and then Submit.\nModel access should take affect momentarily, you can verify it by looking at the Access status column.\nYou should see your models inside Model Catalog. This wraps up the model access configuration, in the next section you will learn how to use these models in the application.",
    "description": "Access to Amazon Bedrock foundation models isn’t granted by default. In order to gain access to the foundational model, follow the steps below.\n:::alert{header=“Model providers” type=“info”} As part of this workshop we will utilize model provider from Amazon, Anthropic, and Cohere. Access to Amazon Titan model is available by default. Access to model in different AWS regions may vary, please refer to the model support by AWS region. :::\nFrom the AWS console, navigate to Amazon Bedrock.",
    "tags": [],
    "title": "OpenAI model access",
    "uri": "/10-pre-requisites/openai-model-access/index.html"
  },
  {
    "breadcrumb": "API Management with Kong Konnect",
    "content": "This chapter will walk you through\nKonnect Control Plane and Data Plane creation using Kong Gateway Operator (KGO). Scale Kong data plane nodes on EKS using horizontal pod Autoscaler. Access Kong data plane through an AWS Load Balancer Here’s a Reference Architecture that will be implemented in this workshop:\nKong Konnect Control Plane: responsible for managing your APIs Kong Konnect Data Plane: connected to the Control Plane, it is responsible for processing all the incoming requests sent by the consumers. Kong provides a plugin framework, where each one of them is responsible for a specific functionality. As a can see, there are two main collections of plugins: On the left, the historic and regular API Gateway plugins, implementing all sort of policies including, for example, OIDC based Authentication processes with Keycloak, Amazon Cognito and Okta or Observability with Prometheus/Grafana and Dynatrace. On the right, another plugin collection for AI-based use cases. For example, the AI Rate Limiting plugin implements policies like this based on the number of tokens consumed be the requests. Or, as another example is the AI Semantic Cache plugin, which caches data based on the semantics related to the responses coming from the LLM models. Kong AI Gateway supports, out of the box, a variety of infrastructures, including not just OpenAI, but also Amazon Bedrock, Google Gemini, Mistral, Anthropic, etc. In order to deal with embeddings, the Gateway also supports also vector databases. Kong Gateway protects not just the LLM Models but also the upstream services, including your application micros surfaces or services. Konnect Control Plane After Konnect registration, you need to create your first Control Plane. There are multiple ways to do it:\nKonnect User Interface. RESTful Admin API, a fundamental mechanism for administration purposes. Kong Gateway Operator (KGO) and Kubernetes CRDs To get an easier and faster deployment, this workshop uses KGO. You may observe the output in Konnect UI.\nThis tutorial is intended to be used for labs and PoC only. There are many aspects and processes, typically implemented in production sites, not described here. For example: Digital Certificate issuing, Cluster monitoring, etc. For a production ready deployment, refer Kong on Terraform Constructs, available here\nYou can now click Next to begin the module.",
    "description": "This chapter will walk you through\nKonnect Control Plane and Data Plane creation using Kong Gateway Operator (KGO). Scale Kong data plane nodes on EKS using horizontal pod Autoscaler. Access Kong data plane through an AWS Load Balancer Here’s a Reference Architecture that will be implemented in this workshop:\nKong Konnect Control Plane: responsible for managing your APIs Kong Konnect Data Plane: connected to the Control Plane, it is responsible for processing all the incoming requests sent by the consumers. Kong provides a plugin framework, where each one of them is responsible for a specific functionality. As a can see, there are two main collections of plugins: On the left, the historic and regular API Gateway plugins, implementing all sort of policies including, for example, OIDC based Authentication processes with Keycloak, Amazon Cognito and Okta or Observability with Prometheus/Grafana and Dynatrace. On the right, another plugin collection for AI-based use cases. For example, the AI Rate Limiting plugin implements policies like this based on the number of tokens consumed be the requests. Or, as another example is the AI Semantic Cache plugin, which caches data based on the semantics related to the responses coming from the LLM models. Kong AI Gateway supports, out of the box, a variety of infrastructures, including not just OpenAI, but also Amazon Bedrock, Google Gemini, Mistral, Anthropic, etc. In order to deal with embeddings, the Gateway also supports also vector databases. Kong Gateway protects not just the LLM Models but also the upstream services, including your application micros surfaces or services. Konnect Control Plane After Konnect registration, you need to create your first Control Plane. There are multiple ways to do it:",
    "tags": [],
    "title": "Konnect Setup",
    "uri": "/11-konnect-setup/index.html"
  },
  {
    "breadcrumb": "API Management with Kong Konnect \u003e Konnect Setup",
    "content": "PAT (Personal Access Token) KGO requires a Konnect Personal Access Token (PAT) for creating the Control Plane. To generate your PAT, click on your initials in the upper right corner of the Konnect home page, then select Personal Access Tokens. Click on + Generate Token, name your PAT, set its expiration time, and be sure to copy and save it, as Konnect won’t display it again.\nNote Be sure to copy and save PAT, as Konnect won’t display it again.\nKonnect PAT secret Create a Kubernetes (K8) Secret with your PAT in the kong namespace. KGO requires the secret to be labeled.\nSave PAT in your CloudShell environment variables echo \"export PAT=PASTE_THE_CONTENTS_OF_COPIED_PAT\" \u003e\u003e ~/.bashrc bash Note Pls don’t forget to replace PASTE_THE_CONTENTS_OF_COPIED_PAT in the below command with the copied PAT from Kong UI.\nCreate the namespace and Kubernetes Service Account The Kubernetes Service Account will be used to deploy the Kong Data Plane. kubectl create namespace kong kubectl create sa kaigateway-podid-sa -n kong Note Pls DO NOT modify the service account name. Pod Identities and the respective IAM permissions are specifically associated with this name.\nCreate K8 Secret with PAT Note Pls don’t forget to replace PASTE_THE_CONTENTS_OF_COPIED_PAT in the below command with the copied PAT from Kong UI.\nkubectl create secret generic konnect-pat -n kong --from-literal=token=$(echo $PAT) kubectl label secret konnect-pat -n kong \"konghq.com/credential=konnect\" You can now click Next to install the operator.",
    "description": "PAT (Personal Access Token) KGO requires a Konnect Personal Access Token (PAT) for creating the Control Plane. To generate your PAT, click on your initials in the upper right corner of the Konnect home page, then select Personal Access Tokens. Click on + Generate Token, name your PAT, set its expiration time, and be sure to copy and save it, as Konnect won’t display it again.",
    "tags": [],
    "title": "Personal Access Token",
    "uri": "/11-konnect-setup/111-personal-access-token/index.html"
  },
  {
    "breadcrumb": "API Management with Kong Konnect \u003e Konnect Setup",
    "content": "Install the Operator To get started let’s install the Operator:\nhelm repo add kong https://charts.konghq.com helm repo update kong helm upgrade --install kgo kong/gateway-operator \\ -n kong-system \\ --create-namespace \\ --set image.tag=1.6 \\ --set kubernetes-configuration-crds.enabled=true \\ --set env.ENABLE_CONTROLLER_KONNECT=true You can check the Operator’s log with: kubectl logs $(kubectl get pod -n kong-system -o json | jq -r '.items[].metadata | select(.name | startswith(\"kgo-gateway-operator\"))' | jq -r '.name') -n kong-system Kong-gratulations! have now reached the end of this module by creating a Kong Operator. You can now click Next to proceed with the next module.",
    "description": "Install the Operator To get started let’s install the Operator:\nhelm repo add kong https://charts.konghq.com helm repo update kong helm upgrade --install kgo kong/gateway-operator \\ -n kong-system \\ --create-namespace \\ --set image.tag=1.6 \\ --set kubernetes-configuration-crds.enabled=true \\ --set env.ENABLE_CONTROLLER_KONNECT=true You can check the Operator’s log with: kubectl logs $(kubectl get pod -n kong-system -o json | jq -r '.items[].metadata | select(.name | startswith(\"kgo-gateway-operator\"))' | jq -r '.name') -n kong-system Kong-gratulations! have now reached the end of this module by creating a Kong Operator. You can now click Next to proceed with the next module.",
    "tags": [],
    "title": "Kong Gateway Operator",
    "uri": "/11-konnect-setup/112-kgo-installation/index.html"
  },
  {
    "breadcrumb": "API Management with Kong Konnect \u003e Konnect Setup",
    "content": "Control Plane Deployment The following declaration defines an Authentication Configuration, based on the Kubernetes Secret and referring to a Konnect API URL, and the actual Konnect Control Plane.\ncat \u003c\u003cEOF | kubectl apply -f - kind: KonnectAPIAuthConfiguration apiVersion: konnect.konghq.com/v1alpha1 metadata: name: konnect-api-auth-conf namespace: kong spec: type: secretRef secretRef: name: konnect-pat namespace: kong serverURL: us.api.konghq.com --- kind: KonnectGatewayControlPlane apiVersion: konnect.konghq.com/v1alpha1 metadata: name: kong-aws namespace: kong spec: name: kong-aws konnect: authRef: name: konnect-api-auth-conf EOF Expected Sample Output\nkonnectapiauthconfiguration.konnect.konghq.com/konnect-api-auth-conf created konnectgatewaycontrolplane.konnect.konghq.com/kong-aws created If you go to Konnect UI \u003e Gateway manager, you should see a new control plane named kong-aws getting created.\nData Plane deployment The next declaration instantiates a Data Plane connected to your Control Plane. It creates a KonnectExtension, asking KGO to manage the certificate and private key provisioning automatically, and the actual Data Plane. The Data Plane declaration specifies the Docker image, in our case 3.10, as well as how the Kubernetes Service, related to the Data Plane, should be created. Also, we use the the Data Plane deployment refers to the Kubernetes Service Account we created before.\ncat \u003c\u003cEOF | kubectl apply -f - kind: KonnectExtension apiVersion: konnect.konghq.com/v1alpha1 metadata: name: konnect-config1 namespace: kong spec: clientAuth: certificateSecret: provisioning: Automatic konnect: controlPlane: ref: type: konnectNamespacedRef konnectNamespacedRef: name: kong-aws --- apiVersion: gateway-operator.konghq.com/v1beta1 kind: DataPlane metadata: name: dataplane1 namespace: kong spec: extensions: - kind: KonnectExtension name: konnect-config1 group: konnect.konghq.com deployment: podTemplateSpec: spec: containers: - name: proxy image: kong/kong-gateway:3.10.0.1 serviceAccountName: kaigateway-podid-sa network: services: ingress: name: proxy1 type: LoadBalancer annotations: \"service.beta.kubernetes.io/aws-load-balancer-scheme\": \"internet-facing\" \"service.beta.kubernetes.io/aws-load-balancer-nlb-target-type\": \"ip\" EOF Note Pls DO NOT modify the serviceAccountName. Pod Identities and the respective IAM permissions are specfically associated with this name.\nIt takes some minutes to get the Load Balancer provisioned and avaiable. Get its domain name with:\necho \"export DATA_PLANE_LB=$(kubectl get svc -n kong proxy1 --output=jsonpath='{.status.loadBalancer.ingress[0].hostname}')\" \u003e\u003e ~/.bashrc bash View the load balancer DNS as\necho $DATA_PLANE_LB Try calling it as\ncurl -w '\\n' $DATA_PLANE_LB Expected Output\n{ \"message\":\"no Route matched with those values\", \"request_id\":\"d364362a60b32142fed73712a9ea1948\" } Further Reading Kong Konnect API auth configuration Kong-gratulations! have now reached the end of this module by creating control plane and data plane. You can now click Next to proceed with the next module.",
    "description": "Control Plane Deployment The following declaration defines an Authentication Configuration, based on the Kubernetes Secret and referring to a Konnect API URL, and the actual Konnect Control Plane.\ncat \u003c\u003cEOF | kubectl apply -f - kind: KonnectAPIAuthConfiguration apiVersion: konnect.konghq.com/v1alpha1 metadata: name: konnect-api-auth-conf namespace: kong spec: type: secretRef secretRef: name: konnect-pat namespace: kong serverURL: us.api.konghq.com --- kind: KonnectGatewayControlPlane apiVersion: konnect.konghq.com/v1alpha1 metadata: name: kong-aws namespace: kong spec: name: kong-aws konnect: authRef: name: konnect-api-auth-conf EOF Expected Sample Output",
    "tags": [],
    "title": "Control Plane and Data Plane",
    "uri": "/11-konnect-setup/113-cp-dp/index.html"
  },
  {
    "breadcrumb": "API Management with Kong Konnect \u003e Konnect Setup",
    "content": "One of the most important capabilities provided by Kubernetes is to easily scale out a Deployment. With a single command we can create or terminate pod replicas in order to optimally support a given throughput.\nThis capability is especially interesting for Kubernetes applications like Kong for Kubernetes Ingress Controller.\nHere’s our deployment before scaling it out:\nkubectl get service -n kong Sample Output\nNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE dataplane-admin-dataplane1-x9n6r ClusterIP None \u003cnone\u003e 8444/TCP 20h proxy1 LoadBalancer 10.100.234.223 k8s-kong-proxy1-518c8abdcc-a10b0ef08ae8ba02.elb.us-east-2.amazonaws.com 80:32290/TCP,443:31084/TCP 20h Notice, at this point in the workshop, there is only one pod taking data plane traffic.\nkubectl get pod -n kong -o wide Sample Output\nNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES dataplane-dataplane1-ch6g9-6889fdf76b-5gjh9 1/1 Running 0 20h 192.168.61.40 ip-192-168-44-68.us-east-2.compute.internal \u003cnone\u003e \u003cnone\u003e Manual Scaling Out Now, let’s scale the deployment out creating 3 replicas of the pod\ncat \u003c\u003cEOF | kubectl apply -f - apiVersion: gateway-operator.konghq.com/v1beta1 kind: DataPlane metadata: name: dataplane1 namespace: kong spec: extensions: - kind: KonnectExtension name: konnect-config1 group: konnect.konghq.com deployment: podTemplateSpec: spec: containers: - name: proxy image: kong/kong-gateway:3.10.0.1 serviceAccountName: kaigateway-podid-sa replicas: 3 network: services: ingress: name: proxy1 type: LoadBalancer annotations: \"service.beta.kubernetes.io/aws-load-balancer-scheme\": \"internet-facing\" \"service.beta.kubernetes.io/aws-load-balancer-nlb-target-type\": \"ip\" EOF Check the Deployment again and now you should see 3 replicas of the pod.\n:::code{showCopyAction=true showLineNumbers=false language=shell} kubectl get pod -n kong -o wide :::\nSample Output\nNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES dataplane-dataplane1-ch6g9-6889fdf76b-5gjh9 1/1 Running 0 20h 192.168.61.40 ip-192-168-44-68.us-east-2.compute.internal \u003cnone\u003e \u003cnone\u003e dataplane-dataplane1-ch6g9-6889fdf76b-9gt4s 1/1 Running 0 6m15s 192.168.52.45 ip-192-168-44-68.us-east-2.compute.internal \u003cnone\u003e \u003cnone\u003e dataplane-dataplane1-ch6g9-6889fdf76b-mrjdx 1/1 Running 0 6m15s 192.168.36.12 ip-192-168-44-68.us-east-2.compute.internal \u003cnone\u003e \u003cnone\u003e As we can see, the 2 new Pods have been created and are up and running. If we check our Kubernetes Service again, we will see it has been updated with the new IP addresses. That allows the Service to implement Load Balancing across the Pod replicas.\n:::code{showCopyAction=true showLineNumbers=false language=shell} kubectl describe service proxy1 -n kong :::\nSample Output\nName: proxy1 Namespace: kong Labels: app=dataplane1 gateway-operator.konghq.com/dataplane-service-state=live gateway-operator.konghq.com/dataplane-service-type=ingress gateway-operator.konghq.com/managed-by=dataplane Annotations: gateway-operator.konghq.com/last-applied-annotations: {\"service.beta.kubernetes.io/aws-load-balancer-nlb-target-type\":\"ip\",\"service.beta.kubernetes.io/aws-load-balancer-scheme\":\"internet-facin... service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: ip service.beta.kubernetes.io/aws-load-balancer-scheme: internet-facing Selector: app=dataplane1,gateway-operator.konghq.com/selector=2231a2f4-f440-4453-98a4-872ed899169b Type: LoadBalancer IP Family Policy: SingleStack IP Families: IPv4 IP: 10.100.234.223 IPs: 10.100.234.223 LoadBalancer Ingress: k8s-kong-proxy1-518c8abdcc-a10b0ef08ae8ba02.elb.us-east-2.amazonaws.com Port: http 80/TCP TargetPort: 8000/TCP NodePort: http 32290/TCP Endpoints: 192.168.61.40:8000,192.168.36.12:8000,192.168.52.45:8000 Port: https 443/TCP TargetPort: 8443/TCP NodePort: https 31084/TCP Endpoints: 192.168.61.40:8443,192.168.36.12:8443,192.168.52.45:8443 Session Affinity: None External Traffic Policy: Cluster Internal Traffic Policy: Cluster Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal SuccessfullyReconciled 13m (x2 over 20h) service Successfully reconciled Reduce the number of Pods to 1 again running as now we will turn on Horizontal pod autoscalar.\ncat \u003c\u003cEOF | kubectl apply -f - apiVersion: gateway-operator.konghq.com/v1beta1 kind: DataPlane metadata: name: dataplane1 namespace: kong spec: extensions: - kind: KonnectExtension name: konnect-config1 group: konnect.konghq.com deployment: podTemplateSpec: spec: containers: - name: proxy image: kong/kong-gateway:3.10.0.1 serviceAccountName: kaigateway-podid-sa replicas: 1 network: services: ingress: name: proxy1 type: LoadBalancer annotations: \"service.beta.kubernetes.io/aws-load-balancer-scheme\": \"internet-facing\" \"service.beta.kubernetes.io/aws-load-balancer-nlb-target-type\": \"ip\" EOF HPA - Horizontal Autoscaler HPA (“Horizontal Pod Autoscaler”) is the Kubernetes resource to automatically control the number of replicas of Pods. With HPA, Kubernetes is able to support the requests produced by the consumers, keeping a given Service Level.\nBased on CPU utilization or custom metrics, HPA starts and terminates Pods replicas updating all service data to help on the load balancing policies over those replicas.\nHPA is described at https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/. Also, there’s a nice walkthrough at https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/\nKubernetes defines its own units for cpu and memory. You can read more about it at: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/. We use these units to set our Deployments with HPA.\nMetrics Server HPA relies no the Metrics Server to control the number of replicas of a given deployment. Check it as follows:\nkubectl get pod -n kube-system -o json | jq -r '.items[].metadata | select(.name | startswith(\"metrics-server-\"))' | jq -r '.name' Now you should see two metrics-server- pods in Running state\nSample Output\nmetrics-server-84cbf4fd8-9fblt metrics-server-84cbf4fd8-zw6hs Turn HPA on Still using the Operator, let’s upgrade our Data Plane deployment including new and specific settings for HPA. The new settings are defining the ammount of CPU and memory each Pod should allocate. At the same time, the “scaling” sets are telling HPA how to proceed to instantiate new Pod replicas.\nHere’s the final declaration:\ncat \u003c\u003cEOF | kubectl apply -f - apiVersion: gateway-operator.konghq.com/v1beta1 kind: DataPlane metadata: name: dataplane1 namespace: kong spec: extensions: - kind: KonnectExtension name: konnect-config1 group: konnect.konghq.com deployment: podTemplateSpec: spec: containers: - name: proxy image: kong/kong-gateway:3.10.0.1 resources: requests: memory: \"300Mi\" cpu: \"300m\" limits: memory: \"800Mi\" cpu: \"1200m\" serviceAccountName: kaigateway-podid-sa scaling: horizontal: minReplicas: 1 maxReplicas: 20 metrics: - type: Resource resource: name: cpu target: type: Utilization averageUtilization: 20 EOF Checking HPA After submitting the command check the Deployment again. Since we’re not consume the Data Plane, we are supposed to see a single Pod running. In the next sections we’re going to send requests to the Data Plane and new Pod will get created to handle them.\nkubectl get pod -n kong Sample Output\nNAME READY STATUS RESTARTS AGE dataplane-dataplane1-ch6g9-5fb9c6484b-kklw5 1/1 Running 0 73s You can check the HPA status with:\nkubectl get hpa -n kong Send traffic\nWe are going to use Fortio to consume the Data Plane and see the HPA in action. Note we are interested on sending traffic to the Data Plane only, so we are consuming a non-existing Route.\ncat \u003c\u003cEOF | kubectl apply -f - apiVersion: v1 kind: Pod metadata: name: fortio labels: app: fortio spec: containers: - name: fortio image: fortio/fortio args: [\"load\", \"-c\", \"800\", \"-qps\", \"3000\", \"-t\", \"20m\", \"-allow-initial-errors\", \"http://proxy1.kong.svc.cluster.local:80/route1/get\"] EOF Sample Output\nEventually, HPA will start a new replica:\n% kubectl get hpa -n kong NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE dataplane1 Deployment/dataplane-dataplane1-ch6g9 cpu: 2%/75% 1 20 2 14m % kubectl get pod -n kong -o json | jq -r '.items[].metadata.name' dataplane-dataplane1-ch6g9-8c6c9cfcd-qbqp5 dataplane-dataplane1-ch6g9-8c6c9cfcd-rxcwm If you delete the Fortio pod, HPA should terminate one pod and get back to 1 replica only. kubectl delete pod fortio Delete HPA\nDelete the HPA setting applying the original declaration\ncat \u003c\u003cEOF | kubectl apply -f - apiVersion: gateway-operator.konghq.com/v1beta1 kind: DataPlane metadata: name: dataplane1 namespace: kong spec: extensions: - kind: KonnectExtension name: konnect-config1 group: konnect.konghq.com deployment: podTemplateSpec: spec: containers: - name: proxy image: kong/kong-gateway:3.10.0.1 serviceAccountName: kaigateway-podid-sa replicas: 1 network: services: ingress: name: proxy1 type: LoadBalancer annotations: \"service.beta.kubernetes.io/aws-load-balancer-scheme\": \"internet-facing\" \"service.beta.kubernetes.io/aws-load-balancer-nlb-target-type\": \"ip\" EOF Kong-gratulations! have now reached the end of this module by implementing and successfully testing Horizontal Pod AutoScaling. You can now click Next to proceed with the next chapter.",
    "description": "One of the most important capabilities provided by Kubernetes is to easily scale out a Deployment. With a single command we can create or terminate pod replicas in order to optimally support a given throughput.\nThis capability is especially interesting for Kubernetes applications like Kong for Kubernetes Ingress Controller.\nHere’s our deployment before scaling it out:\nkubectl get service -n kong Sample Output\nNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE dataplane-admin-dataplane1-x9n6r ClusterIP None \u003cnone\u003e 8444/TCP 20h proxy1 LoadBalancer 10.100.234.223 k8s-kong-proxy1-518c8abdcc-a10b0ef08ae8ba02.elb.us-east-2.amazonaws.com 80:32290/TCP,443:31084/TCP 20h Notice, at this point in the workshop, there is only one pod taking data plane traffic.",
    "tags": [],
    "title": "Data Plane Elasticity",
    "uri": "/11-konnect-setup/114-elasticity/index.html"
  },
  {
    "breadcrumb": "API Management with Kong Konnect",
    "content": "In this second part of the workshop we are going to explore the AI capabilities provides by Kong AI Gateway and the specific collection of plugins.\nYou can now click Next to begin the module.\nOptional Reading Learn more about Kong AI Gateway",
    "description": "In this second part of the workshop we are going to explore the AI capabilities provides by Kong AI Gateway and the specific collection of plugins.\nYou can now click Next to begin the module.\nOptional Reading Learn more about Kong AI Gateway",
    "tags": [],
    "title": "Kong AI Gateway",
    "uri": "/16-ai-gateway/index.html"
  },
  {
    "breadcrumb": "API Management with Kong Konnect",
    "content": "With our Control Plane created and Data Plane layer deployed it’s time to create an API and expose an application. In this module, we will\nDeploy an application to get protected by the Data Plane Use decK to define a Kong Service based on an endpoint provided by the application and a Kong Route on top of the Kong Service to expose the application. Enable Kong Plugins to the Kong Route or Kong Service. Define Kong Consumers to represent the entities sending request to the Gateway and enable Kong Plugin to them. With decK (declarations for Kong) you can manage Kong Konnect configuration in a declaratively way.\ndecK operates on state files. decK state files describe the configuration of Kong API Gateway. State files encapsulate the complete configuration of Kong in a declarative format, including services, routes, plugins, consumers, and other entities that define how requests are processed and routed through Kong.\nYou can now click Next to begin the module.\nOptional Reading Learn more about Konnect Gateway Manager",
    "description": "With our Control Plane created and Data Plane layer deployed it’s time to create an API and expose an application. In this module, we will\nDeploy an application to get protected by the Data Plane Use decK to define a Kong Service based on an endpoint provided by the application and a Kong Route on top of the Kong Service to expose the application. Enable Kong Plugins to the Kong Route or Kong Service. Define Kong Consumers to represent the entities sending request to the Gateway and enable Kong Plugin to them. With decK (declarations for Kong) you can manage Kong Konnect configuration in a declaratively way.",
    "tags": [],
    "title": "Kong API Gateway",
    "uri": "/12-api-gateway/index.html"
  },
  {
    "breadcrumb": "",
    "content": "Introduction Kong Konnect is an API lifecycle management platform delivered as a service. The management plane is hosted in the cloud by Kong, while the runtime environments are deployed in your AWS accounts. Management plane enables customers to securely execute API management activities such as create API routes, define services etc. Runtime environments connect with the management plane using mutual transport layer authentication (mTLS), receive the updates and take customer facing API traffic.\nLearning Objectives In this workshop, you will:\nGet an architectural overview of Kong Konnect platform. Set up Konnect runtime on Amazon Elastic Kubernetes Service (EKS). Learn what are services, routes and plugin. Deploy a sample microservice and access the application using the defined route. Use the platform to address the following API Gateway use cases Authentication and Authorization Rate limiting Response Transformer Proxy caching And the following AI Gateway use cases Prompt Engineering LLM-based Request and Reponse transformation Semantic Caching Token-based Rate Limiting Semantic Routing RAG - Retrieval-Augmented Generation Expected Duration Pre-Requisite Environment Setup (20 minutes) Architectural Walkthrough (10 minutes) Sample Application and addressing the use cases (60 minutes) Next Steps and Cleanup (5 min) :::alert{header=“Important” type=“warning”}\nRunning this workshop in your own AWS account will incur ~ $1 per hour charges. Please ensure to cleanup, once you fulfill your learning objectives.",
    "description": "Introduction Kong Konnect is an API lifecycle management platform delivered as a service. The management plane is hosted in the cloud by Kong, while the runtime environments are deployed in your AWS accounts. Management plane enables customers to securely execute API management activities such as create API routes, define services etc. Runtime environments connect with the management plane using mutual transport layer authentication (mTLS), receive the updates and take customer facing API traffic.",
    "tags": [],
    "title": "API Management with Kong Konnect",
    "uri": "/index.html"
  },
  {
    "breadcrumb": "API Management with Kong Konnect",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Categories",
    "uri": "/categories/index.html"
  },
  {
    "breadcrumb": "API Management with Kong Konnect",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tags",
    "uri": "/tags/index.html"
  }
]
