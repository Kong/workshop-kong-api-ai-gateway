<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Prerequisites :: API Management with Kong Konnect</title>
    <link>http://localhost:1313/10-prerequisites/index.html</link>
    <description>Knowledge Attendees should have a intermediate knowledge of Kubernetes and Docker for installations of Konnect Data Plane and other products like Keycloak, Redis, etc.&#xA;Attendees should have a basic knowledge of GenAI models, specially LLMs and Embedding models as well as providers like OpenAI, Mistral, Anthropic, AWS, GCP, Azure.&#xA;Kong Academy Complete two badges via Kong Academy: Kong Gateway Foundations and Kong Gateway Operations&#xA;Kong Konnect Subscription You will need a Kong Konnect Subscription to execute this workshop.</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <atom:link href="http://localhost:1313/10-prerequisites/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Konnect Subscription</title>
      <link>http://localhost:1313/10-prerequisites/konnect-subscription/index.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/10-prerequisites/konnect-subscription/index.html</guid>
      <description>Konnect Plus Subscription You will need a Konnect subscription. Follow the steps below to obtain a Konnect Plus subscription. Initially $500 of credits are provided for up to 30 days, after the credits have expired or the time has finished Konnect Plus will charge based on Konnect Plus pricing. Following the workshop instructions will use less than $500 credits. After the workshop has finished the Konnect Plus environment can be deleted.</description>
    </item>
    <item>
      <title>Minikube</title>
      <link>http://localhost:1313/10-prerequisites/minikube/index.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/10-prerequisites/minikube/index.html</guid>
      <description>We are going to deploy our Data Plane in a Minikube Cluster over Podman. You can start Podman with:&#xA;podman machine set --memory 8196 podman machine start If you want to stop it run: podman machine stop Then you can install Minikube with: minikube start --driver=podman --memory=&#39;no-limit&#39; Use should see your cluster running with: kubectl get all --all-namespaces Typical output is:&#xA;NAMESPACE NAME READY STATUS RESTARTS AGE kube-system pod/coredns-674b8bbfcf-xrllp 0/1 Running 0 12s kube-system pod/etcd-minikube 1/1 Running 0 18s kube-system pod/kube-apiserver-minikube 1/1 Running 0 18s kube-system pod/kube-controller-manager-minikube 1/1 Running 0 18s kube-system pod/kube-proxy-xkfn9 1/1 Running 0 13s kube-system pod/kube-scheduler-minikube 1/1 Running 0 18s kube-system pod/storage-provisioner 1/1 Running 0 17s NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE default service/kubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 19s kube-system service/kube-dns ClusterIP 10.96.0.10 &lt;none&gt; 53/UDP,53/TCP,9153/TCP 18s NAMESPACE NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE kube-system daemonset.apps/kube-proxy 1 1 1 1 1 kubernetes.io/os=linux 18s NAMESPACE NAME READY UP-TO-DATE AVAILABLE AGE kube-system deployment.apps/coredns 0/1 1 0 18s NAMESPACE NAME DESIRED CURRENT READY AGE kube-system replicaset.apps/coredns-674b8bbfcf 1 1 0 12s To be able to consume the Kubernetes Load Balancer Services, in another terminal run: minikube tunnel</description>
    </item>
    <item>
      <title>Redis and Ollama</title>
      <link>http://localhost:1313/10-prerequisites/redis-ollama-keycloak-opa/index.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/10-prerequisites/redis-ollama-keycloak-opa/index.html</guid>
      <description>Install Redis Use the redis-stack Helm Charts to install Redis as our vector database.&#xA;helm repo add redis-stack https://redis-stack.github.io/helm-redis-stack helm repo update helm install redis-stack redis-stack/redis-stack -n redis --create-namespace Check the installation: kubectl exec $(kubectl get pod -n redis -o json | jq -r &#39;.items[].metadata.name&#39;) -n redis -- redis-server --version If you want to uninstall it: helm uninstall redis-stack -n redis kubectl delete namespace redis Install Ollama As our Embedding model, we’re going to consume the “mxbai-embed-large:latest” model handled locally by Ollama. Use the Ollama Helm Charts to install it.</description>
    </item>
  </channel>
</rss>